---
title: 'Wrangling: Longline Data'
output: html_document
---
## Setup
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# packages
library(tidyverse)
library(dplyr)
library(here)
library(anytime)

# working directory
here()

# longline data
longline_full <- read.csv(here("Data", "Raw", "Longline_full"))

# preserve raw data
## write.csv(longline_full, here("Data", "Raw", "Longline_full"))


```

## Data exploration
```{r cars}
str(longline_full)
head(longline_full)

# how many individual vessels are included in this dataset
unique(longline_full$mmsi)
class(longline_full$mmsi)
longline_full$mmsi <- as.factor(longline_full$mmsi)
# there are two vessels in this dataset
# how many records (location points) does each vessel have ??
nrow(longline_full)
```
## Processing Data
```{r}
# select desired fields
  # eliminated 'course' and 'source' because I don't expect them to be as useful predictor variables, now I'm left with 8 columns
longline_select <- 
  select(longline_full, mmsi, timestamp, distance_from_shore, distance_from_port,
         speed, lat, lon, is_fishing) 


# is_fishing field: 0's = unknown, how many 0's, 1's and -1's do we have (out of 65,499 rows)
count(longline_select, longline_select$is_fishing == 0) # 1,397 'not fishing' statuses (2.13%)
count(longline_select, longline_select$is_fishing == 1) # 2,792 'fishing' statuses (4.26%)
count(longline_select, longline_select$is_fishing == -1) # 61,310 'no data' statuses (93.6%)

# percentages
1397/65499 # zeros
2792/65499 # fishing
61310/65499 # not fishing

1397 + 2792
```

## Cleaning up fields
```{r}
# Clean up is_fishing field
  # I will eliminate records with zero (unknown) value in is_fishing field because I want to see how   well different variables predict a binary condition of fishing or not fishing
longline_fishing <- filter(longline_select, is_fishing %in% c(0, 1))

str(longline_fishing)

# Reformatting timestamp (converting unix timestamp to regular date time)
class(longline_fishing$timestamp)

## first dictated timestamp column as unix
longline_fishing$timestamp <- as.POSIXct(longline_fishing$timestamp, origin="1970-01-01")

## them convert to regulat date time
longline_fishing_recode <- mutate(longline_fishing, date = anytime(longline_fishing$timestamp))

str(longline_fishing_recode)

## separate into date and time columns
longline_fishing_separate <- separate(longline_fishing_recode, timestamp, c("Date", "Time"), sep = " ")

# rename vessels
## reformat to factor
str(longline_fishing_separate)
longline_fishing_separate$mmsi <- as.factor(longline_fishing_separate$mmsi) 

## change names
longline_fishing_separate$mmsi <- recode(longline_fishing_separate$mmsi, "12639560807591" = "Vessel 1", "51394439323066" = "Vessel 2")

# reformat date and time columns
longline_fishing_separate$Date <- as.Date(longline_fishing_separate$Date, format = "%Y-%m-%d") 
# longline_fishing_separate$Time <- as.POSIXct(longline_fishing_separate$Time,format="%H:%M:%S")

str(longline_fishing_separate)  

# reformat is_fishing field
longline_fishing_separate$is_fishing <- as.factor(longline_fishing_separate$is_fishing)
```
## Organize and save processed data
```{r}
colnames(longline_fishing_separate)
str(longline_fishing_separate)

# reorder and rename data frame columns
longline_processed <- 
  select(longline_fishing_separate, mmsi, Date, Time, lat, lon, speed, distance_from_shore, distance_from_port, is_fishing)

str(longline_processed)

# save as processed file
here()
write.csv(longline_processed, here("Data", "Processed", "Longline_Processed.csv"))
   
```

## Exploration and processing notes

> general stats question <
  # to have only 4% of our cases be fishing and the other 93% be not fishing..
  how effective is our model going to be?
  ## ..initially she said..there might be some weirdness in the model..
  ## but we could equalize the sample sizes by choosing 2,000 points from each

> potential model questions <
  # how does speed correlate with fishing vs not fishing
  # look spatially at where the vessels are fishing
  # look at what times vessels are fishing
    # what types of gaps are possible in getting 'fishing' data
        # based on data collection/algorithm - how does it mark 'fishing'
        # are there constraints on when/what time data is collected? cloud cover, etc.?

> ways to further organize data
  # eliminate unknown cases to just have binary (fishing, not fishing)
  # group_by(vessel, is_fishing)
  # visualize where vessels are fishing, where vessels are not fishing
> general exploratin
  # check out the map, how far are points scattered? 
  # how should we pick sample size? (random sample? choose sample within an area?)
  
> ways to organize report
  # new code chunk every time I make a new data frame?
  # new data frame every time I change the fields significantly?
  # new markdown section every time I'm explaining the next step
  # each script is one big task in the project (e.g., processing longline data is all in one script,
  processing additional csv data will be in a separate script to keep everything clean)


